import time
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
import re
from difflib import SequenceMatcher

from OSMPythonTools.nominatim import Nominatim
from OSMPythonTools.overpass import Overpass

# -----------------------------
# NLP —Ñ—É–Ω–∫—Ü–∏–∏
# -----------------------------

def normalize_text(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É, —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤"""
    if not text:
        return ""
    text = text.lower().strip()
    text = re.sub(r'\s+', ' ', text)
    return text

def generate_name_variants(full_name):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∏–º–µ–Ω–∏ –≥–µ—Ä–æ—è
    """
    variants = set()
    parts = full_name.split()
    
    if len(parts) >= 2:
        # –§–∞–º–∏–ª–∏—è
        variants.add(parts[-1])
        # –ü–æ–ª–Ω–æ–µ –∏–º—è
        variants.add(full_name)
        # –ò–Ω–∏—Ü–∏–∞–ª + —Ñ–∞–º–∏–ª–∏—è
        variants.add(f"{parts[0][0]}. {parts[-1]}")
        # –ò–º—è + —Ñ–∞–º–∏–ª–∏—è
        if len(parts) >= 2:
            variants.add(f"{parts[0]} {parts[-1]}")
        
        # –í–∞—Ä–∏–∞–Ω—Ç—ã –ø–∞–¥–µ–∂–µ–π –¥–ª—è —Ñ–∞–º–∏–ª–∏–∏
        surname = parts[-1]
        if surname.endswith('–∞—è'):
            variants.add(surname[:-2] + '–æ–π')
        if surname.endswith('–∏–π'):
            variants.add(surname[:-2] + '–æ–≥–æ')
    
    return list(variants)

def fuzzy_match(street_name, hero_variants, threshold=0.85):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —É–ª–∏—Ü—ã –∏–º—è –≥–µ—Ä–æ—è
    """
    street_normalized = normalize_text(street_name)
    
    for variant in hero_variants:
        variant_normalized = normalize_text(variant)
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if variant_normalized in street_normalized:
            return True
        
        # –ù–µ—á–µ—Ç–∫–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        ratio = SequenceMatcher(None, street_normalized, variant_normalized).ratio()
        if ratio >= threshold:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å–ª–æ–≤–∞–º
        street_words = street_normalized.split()
        for word in street_words:
            if len(word) > 3:
                ratio = SequenceMatcher(None, word, variant_normalized).ratio()
                if ratio >= threshold:
                    return True
    
    return False

def extract_unique_hero_streets(ways_result, hero_variants):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –£–ù–ò–ö–ê–õ–¨–ù–´–ï –Ω–∞–∑–≤–∞–Ω–∏—è —É–ª–∏—Ü, –Ω–∞–∑–≤–∞–Ω–Ω—ã—Ö –≤ —á–µ—Å—Ç—å –≥–µ—Ä–æ—è
    """
    unique_streets = set()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º set –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    
    try:
        for way in ways_result.ways():
            street_name = way.tag('name')
            if street_name and fuzzy_match(street_name, hero_variants):
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                normalized_name = normalize_text(street_name)
                unique_streets.add(normalized_name)
    except:
        pass
    
    return unique_streets

# -----------------------------
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# -----------------------------

HEROES = {
    "–ó–æ—è –ö–æ—Å–º–æ–¥–µ–º—å—è–Ω—Å–∫–∞—è": None
}

# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–º–µ–Ω
HEROES_VARIANTS = {}
for hero in HEROES.keys():
    HEROES_VARIANTS[hero] = generate_name_variants(hero)
    print(f"–í–∞—Ä–∏–∞–Ω—Ç—ã –¥–ª—è {hero}: {HEROES_VARIANTS[hero]}")

# –°–ø–∏—Å–æ–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤ –†–§
RUSSIAN_REGIONS = [
    "Republic of Adygea",
    "Republic of Bashkortostan",
    "Republic of Buryatia",
    "Republic of Altai",
    "Republic of Dagestan",
    "Republic of Ingushetia",
    "Kabardino-Balkarian Republic",
    "Republic of Kalmykia",
    "Karachay-Cherkess Republic",
    "Republic of Karelia",
    "Komi Republic",
    "Republic of Crimea",
    "Republic of Mari El",
    "Republic of Mordovia",
    "Republic of Sakha",
    "Republic of North Ossetia-Alania",
    "Republic of Tatarstan",
    "Republic of Tuva",
    "Udmurt Republic",
    "Republic of Khakassia",
    "Chechen Republic",
    "Chuvash Republic",

    "Altai Krai",
    "Zabaykalsky Krai",
    "Kamchatka Krai",
    "Krasnodar Krai",
    "Krasnoyarsk Krai",
    "Perm Krai",
    "Primorsky Krai",
    "Stavropol Krai",
    "Khabarovsk Krai",

    "Amur Oblast",
    "Arkhangelsk Oblast",
    "Astrakhan Oblast",
    "Belgorod Oblast",
    "Bryansk Oblast",
    "Vladimir Oblast",
    "Volgograd Oblast",
    "Vologda Oblast",
    "Voronezh Oblast",
    "Ivanovo Oblast",
    "Irkutsk Oblast",
    "Kaliningrad Oblast",
    "Kaluga Oblast",
    "Kemerovo Oblast",
    "Kirov Oblast",
    "Kostroma Oblast",
    "Kurgan Oblast",
    "Kursk Oblast",
    "Leningrad Oblast",
    "Lipetsk Oblast",
    "Magadan Oblast",
    "Moscow Oblast",
    "Murmansk Oblast",
    "Nizhny Novgorod Oblast",
    "Novgorod Oblast",
    "Novosibirsk Oblast",
    "Omsk Oblast",
    "Orenburg Oblast",
    "Oryol Oblast",
    "Penza Oblast",
    "Pskov Oblast",
    "Rostov Oblast",
    "Ryazan Oblast",
    "Samara Oblast",
    "Saratov Oblast",
    "Sakhalin Oblast",
    "Sverdlovsk Oblast",
    "Smolensk Oblast",
    "Tambov Oblast",
    "Tver Oblast",
    "Tomsk Oblast",
    "Tula Oblast",
    "Tyumen Oblast",
    "Ulyanovsk Oblast",
    "Chelyabinsk Oblast",
    "Yaroslavl Oblast",

    "Moscow",
    "Saint Petersburg",
    "Sevastopol",

    "Jewish Autonomous Oblast",
    "Nenets Autonomous Okrug",
    "Khanty-Mansi Autonomous Okrug",
    "Chukotka Autonomous Okrug",
    "Yamalo-Nenets Autonomous Okrug"
]

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
nominatim = Nominatim()
overpass = Overpass()

# -----------------------------
# –ü–æ–ª—É—á–∞–µ–º areaId –¥–ª—è —Ä–µ–≥–∏–æ–Ω–æ–≤
# -----------------------------
area_ids = {}
for region in tqdm(RUSSIAN_REGIONS, desc="–ü–æ–ª—É—á–∞–µ–º areaId"):
    try:
        area = nominatim.query(f"{region}, Russia")
        try:
            area_id = area.areaId()
        except AttributeError:
            area_id = area.osmId() + 3600000000
        area_ids[region] = area_id
        time.sleep(1)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {region}: {e}")
        area_ids[region] = None

# -----------------------------
# –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö - –¢–û–õ–¨–ö–û –£–ù–ò–ö–ê–õ–¨–ù–´–ï –£–õ–ò–¶–´
# -----------------------------
data = []
detailed_streets = []

for region, area_id in tqdm(area_ids.items(), desc="–°–±–æ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"):
    for hero, variants in HEROES_VARIANTS.items():
        if not area_id:
            data.append({"–†–µ–≥–∏–æ–Ω": region, "–ì–µ—Ä–æ–π": hero, "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü": 0})
            continue

        query = f"""
        area({area_id})->.searchArea;
        (
          way["highway"]["name"~".", i](area.searchArea);
          relation["highway"]["name"~".", i](area.searchArea);
        );
        out tags;
        """
        
        try:
            result = overpass.query(query)
            
            # –ü–æ–ª—É—á–∞–µ–º –£–ù–ò–ö–ê–õ–¨–ù–´–ï –Ω–∞–∑–≤–∞–Ω–∏—è —É–ª–∏—Ü
            unique_streets = extract_unique_hero_streets(result, variants)
            count = len(unique_streets)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–∂–¥–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ–π —É–ª–∏—Ü–µ
            for street_name in unique_streets:
                detailed_streets.append({
                    "–†–µ–≥–∏–æ–Ω": region,
                    "–ì–µ—Ä–æ–π": hero,
                    "–ù–∞–∑–≤–∞–Ω–∏–µ —É–ª–∏—Ü—ã": street_name
                })
            
            time.sleep(1)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ Overpass –¥–ª—è {hero} –≤ {region}: {e}")
            count = 0

        data.append({"–†–µ–≥–∏–æ–Ω": region, "–ì–µ—Ä–æ–π": hero, "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü": count})

# –°–æ–∑–¥–∞–µ–º DataFrame
df = pd.DataFrame(data)
df.to_csv("streets_by_heroes_unique.csv", index=False, encoding='utf-8-sig')
print("\n‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ streets_by_heroes_unique.csv")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
df_detailed = pd.DataFrame(detailed_streets)
if not df_detailed.empty:
    df_detailed.to_csv("streets_detailed_unique.csv", index=False, encoding='utf-8-sig')
    print("‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ streets_detailed_unique.csv")

# –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –£–ù–ò–ö–ê–õ–¨–ù–´–• —É–ª–∏—Ü: {df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü'].sum()}")
print(f"–†–µ–≥–∏–æ–Ω–æ–≤ —Å —É–ª–∏—Ü–∞–º–∏ –≤ —á–µ—Å—Ç—å –≥–µ—Ä–æ—è: {len(df[df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü'] > 0])}")

# –¢–æ–ø-10 —Ä–µ–≥–∏–æ–Ω–æ–≤
top_10 = df[df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü'] > 0].nlargest(10, '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü')
print(f"\nüèÜ –¢–æ–ø-10 —Ä–µ–≥–∏–æ–Ω–æ–≤:")
for idx, row in top_10.iterrows():
    print(f"  {row['–†–µ–≥–∏–æ–Ω']}: {row['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü']} —É–ª–∏—Ü(—ã)")

# -----------------------------
# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
# -----------------------------
plt.rcParams['font.family'] = 'DejaVu Sans'

for hero in HEROES.keys():
    df_hero = df[(df["–ì–µ—Ä–æ–π"] == hero) & (df["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü"] > 0)]
    df_hero = df_hero.sort_values("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü", ascending=True)

    if df_hero.empty:
        print(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {hero}")
        continue

    plt.figure(figsize=(12, 10))
    plt.barh(df_hero["–†–µ–≥–∏–æ–Ω"], df_hero["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü"], color="skyblue")
    plt.title(f"–£–ª–∏—Ü—ã –≤ —á–µ—Å—Ç—å {hero} (—Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è)", fontsize=14)
    plt.xlabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ª–∏—Ü")
    plt.tight_layout()
    plt.savefig(f"{hero.replace(' ', '_')}_streets_unique.png", dpi=300, bbox_inches='tight')
    plt.show()

print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")